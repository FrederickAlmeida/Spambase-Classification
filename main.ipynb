{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j5WfQqDLWL6T"
      },
      "outputs": [],
      "source": [
        "# data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, RandomizedSearchCV, StratifiedKFold\n",
        "\n",
        "# data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# models\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, make_scorer\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez2qO9KmWL6W"
      },
      "source": [
        "## Lendo o dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F_HakJWEWL6Y"
      },
      "outputs": [],
      "source": [
        "column_names = []\n",
        "with open('data/spambase.names', 'r') as f:\n",
        "    for line in f:\n",
        "\n",
        "        if line.strip().endswith('continuous.'):\n",
        "            column_names.append(line[:line.index(':')])\n",
        "\n",
        "    f.close()\n",
        "\n",
        "column_names.append('spam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1HcTkVOfWL6Z",
        "outputId": "5297a8df-959c-451d-9532-326e62c36465"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>word_freq_make</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.210</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.150</td>\n",
              "      <td>0.060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_address</th>\n",
              "      <td>0.640</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_all</th>\n",
              "      <td>0.640</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.710</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.460</td>\n",
              "      <td>0.770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_3d</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_our</th>\n",
              "      <td>0.320</td>\n",
              "      <td>0.140</td>\n",
              "      <td>1.230</td>\n",
              "      <td>0.630</td>\n",
              "      <td>0.630</td>\n",
              "      <td>1.850</td>\n",
              "      <td>1.920</td>\n",
              "      <td>1.880</td>\n",
              "      <td>0.610</td>\n",
              "      <td>0.190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_over</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.190</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_remove</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.210</td>\n",
              "      <td>0.190</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_internet</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.630</td>\n",
              "      <td>0.630</td>\n",
              "      <td>1.850</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.880</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_order</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.640</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.920</td>\n",
              "      <td>0.060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_mail</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.630</td>\n",
              "      <td>0.630</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.640</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_receive</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.210</td>\n",
              "      <td>0.380</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.960</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_will</th>\n",
              "      <td>0.640</td>\n",
              "      <td>0.790</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.280</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.920</td>\n",
              "      <td>0.640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_people</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_report</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.210</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_addresses</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.140</td>\n",
              "      <td>1.750</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_free</th>\n",
              "      <td>0.320</td>\n",
              "      <td>0.140</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.960</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_business</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_email</th>\n",
              "      <td>1.290</td>\n",
              "      <td>0.280</td>\n",
              "      <td>1.030</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.320</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.150</td>\n",
              "      <td>0.120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_you</th>\n",
              "      <td>1.930</td>\n",
              "      <td>3.470</td>\n",
              "      <td>1.360</td>\n",
              "      <td>3.180</td>\n",
              "      <td>3.180</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.850</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.230</td>\n",
              "      <td>1.670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_credit</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.320</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.530</td>\n",
              "      <td>0.060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_your</th>\n",
              "      <td>0.960</td>\n",
              "      <td>1.590</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.640</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_font</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_000</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.430</td>\n",
              "      <td>1.160</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_money</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.430</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.150</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_hp</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_hpl</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_george</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_650</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_lab</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_labs</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_telnet</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_857</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_data</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.150</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_415</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_85</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_technology</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_1999</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_parts</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_pm</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_direct</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_cs</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_meeting</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_original</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_project</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_re</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_edu</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_table</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word_freq_conference</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>char_freq_;</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>char_freq_(</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.223</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.206</td>\n",
              "      <td>0.271</td>\n",
              "      <td>0.030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>char_freq_[</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>char_freq_!</th>\n",
              "      <td>0.778</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.164</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.181</td>\n",
              "      <td>0.244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>char_freq_$</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.203</td>\n",
              "      <td>0.081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>char_freq_#</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.022</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <td>3.756</td>\n",
              "      <td>5.114</td>\n",
              "      <td>9.821</td>\n",
              "      <td>3.537</td>\n",
              "      <td>3.537</td>\n",
              "      <td>3.000</td>\n",
              "      <td>1.671</td>\n",
              "      <td>2.450</td>\n",
              "      <td>9.744</td>\n",
              "      <td>1.729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <td>61.000</td>\n",
              "      <td>101.000</td>\n",
              "      <td>485.000</td>\n",
              "      <td>40.000</td>\n",
              "      <td>40.000</td>\n",
              "      <td>15.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>11.000</td>\n",
              "      <td>445.000</td>\n",
              "      <td>43.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <td>278.000</td>\n",
              "      <td>1028.000</td>\n",
              "      <td>2259.000</td>\n",
              "      <td>191.000</td>\n",
              "      <td>191.000</td>\n",
              "      <td>54.000</td>\n",
              "      <td>112.000</td>\n",
              "      <td>49.000</td>\n",
              "      <td>1257.000</td>\n",
              "      <td>749.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  0         1         2        3        4  \\\n",
              "word_freq_make                0.000     0.210     0.060    0.000    0.000   \n",
              "word_freq_address             0.640     0.280     0.000    0.000    0.000   \n",
              "word_freq_all                 0.640     0.500     0.710    0.000    0.000   \n",
              "word_freq_3d                  0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_our                 0.320     0.140     1.230    0.630    0.630   \n",
              "word_freq_over                0.000     0.280     0.190    0.000    0.000   \n",
              "word_freq_remove              0.000     0.210     0.190    0.310    0.310   \n",
              "word_freq_internet            0.000     0.070     0.120    0.630    0.630   \n",
              "word_freq_order               0.000     0.000     0.640    0.310    0.310   \n",
              "word_freq_mail                0.000     0.940     0.250    0.630    0.630   \n",
              "word_freq_receive             0.000     0.210     0.380    0.310    0.310   \n",
              "word_freq_will                0.640     0.790     0.450    0.310    0.310   \n",
              "word_freq_people              0.000     0.650     0.120    0.310    0.310   \n",
              "word_freq_report              0.000     0.210     0.000    0.000    0.000   \n",
              "word_freq_addresses           0.000     0.140     1.750    0.000    0.000   \n",
              "word_freq_free                0.320     0.140     0.060    0.310    0.310   \n",
              "word_freq_business            0.000     0.070     0.060    0.000    0.000   \n",
              "word_freq_email               1.290     0.280     1.030    0.000    0.000   \n",
              "word_freq_you                 1.930     3.470     1.360    3.180    3.180   \n",
              "word_freq_credit              0.000     0.000     0.320    0.000    0.000   \n",
              "word_freq_your                0.960     1.590     0.510    0.310    0.310   \n",
              "word_freq_font                0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_000                 0.000     0.430     1.160    0.000    0.000   \n",
              "word_freq_money               0.000     0.430     0.060    0.000    0.000   \n",
              "word_freq_hp                  0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_hpl                 0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_george              0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_650                 0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_lab                 0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_labs                0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_telnet              0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_857                 0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_data                0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_415                 0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_85                  0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_technology          0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_1999                0.000     0.070     0.000    0.000    0.000   \n",
              "word_freq_parts               0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_pm                  0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_direct              0.000     0.000     0.060    0.000    0.000   \n",
              "word_freq_cs                  0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_meeting             0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_original            0.000     0.000     0.120    0.000    0.000   \n",
              "word_freq_project             0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_re                  0.000     0.000     0.060    0.000    0.000   \n",
              "word_freq_edu                 0.000     0.000     0.060    0.000    0.000   \n",
              "word_freq_table               0.000     0.000     0.000    0.000    0.000   \n",
              "word_freq_conference          0.000     0.000     0.000    0.000    0.000   \n",
              "char_freq_;                   0.000     0.000     0.010    0.000    0.000   \n",
              "char_freq_(                   0.000     0.132     0.143    0.137    0.135   \n",
              "char_freq_[                   0.000     0.000     0.000    0.000    0.000   \n",
              "char_freq_!                   0.778     0.372     0.276    0.137    0.135   \n",
              "char_freq_$                   0.000     0.180     0.184    0.000    0.000   \n",
              "char_freq_#                   0.000     0.048     0.010    0.000    0.000   \n",
              "capital_run_length_average    3.756     5.114     9.821    3.537    3.537   \n",
              "capital_run_length_longest   61.000   101.000   485.000   40.000   40.000   \n",
              "capital_run_length_total    278.000  1028.000  2259.000  191.000  191.000   \n",
              "spam                          1.000     1.000     1.000    1.000    1.000   \n",
              "\n",
              "                                 5        6       7         8        9  \n",
              "word_freq_make               0.000    0.000   0.000     0.150    0.060  \n",
              "word_freq_address            0.000    0.000   0.000     0.000    0.120  \n",
              "word_freq_all                0.000    0.000   0.000     0.460    0.770  \n",
              "word_freq_3d                 0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_our                1.850    1.920   1.880     0.610    0.190  \n",
              "word_freq_over               0.000    0.000   0.000     0.000    0.320  \n",
              "word_freq_remove             0.000    0.000   0.000     0.300    0.380  \n",
              "word_freq_internet           1.850    0.000   1.880     0.000    0.000  \n",
              "word_freq_order              0.000    0.000   0.000     0.920    0.060  \n",
              "word_freq_mail               0.000    0.640   0.000     0.760    0.000  \n",
              "word_freq_receive            0.000    0.960   0.000     0.760    0.000  \n",
              "word_freq_will               0.000    1.280   0.000     0.920    0.640  \n",
              "word_freq_people             0.000    0.000   0.000     0.000    0.250  \n",
              "word_freq_report             0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_addresses          0.000    0.000   0.000     0.000    0.120  \n",
              "word_freq_free               0.000    0.960   0.000     0.000    0.000  \n",
              "word_freq_business           0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_email              0.000    0.320   0.000     0.150    0.120  \n",
              "word_freq_you                0.000    3.850   0.000     1.230    1.670  \n",
              "word_freq_credit             0.000    0.000   0.000     3.530    0.060  \n",
              "word_freq_your               0.000    0.640   0.000     2.000    0.710  \n",
              "word_freq_font               0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_000                0.000    0.000   0.000     0.000    0.190  \n",
              "word_freq_money              0.000    0.000   0.000     0.150    0.000  \n",
              "word_freq_hp                 0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_hpl                0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_george             0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_650                0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_lab                0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_labs               0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_telnet             0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_857                0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_data               0.000    0.000   0.000     0.150    0.000  \n",
              "word_freq_415                0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_85                 0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_technology         0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_1999               0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_parts              0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_pm                 0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_direct             0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_cs                 0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_meeting            0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_original           0.000    0.000   0.000     0.300    0.000  \n",
              "word_freq_project            0.000    0.000   0.000     0.000    0.060  \n",
              "word_freq_re                 0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_edu                0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_table              0.000    0.000   0.000     0.000    0.000  \n",
              "word_freq_conference         0.000    0.000   0.000     0.000    0.000  \n",
              "char_freq_;                  0.000    0.000   0.000     0.000    0.040  \n",
              "char_freq_(                  0.223    0.054   0.206     0.271    0.030  \n",
              "char_freq_[                  0.000    0.000   0.000     0.000    0.000  \n",
              "char_freq_!                  0.000    0.164   0.000     0.181    0.244  \n",
              "char_freq_$                  0.000    0.054   0.000     0.203    0.081  \n",
              "char_freq_#                  0.000    0.000   0.000     0.022    0.000  \n",
              "capital_run_length_average   3.000    1.671   2.450     9.744    1.729  \n",
              "capital_run_length_longest  15.000    4.000  11.000   445.000   43.000  \n",
              "capital_run_length_total    54.000  112.000  49.000  1257.000  749.000  \n",
              "spam                         1.000    1.000   1.000     1.000    1.000  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('data/spambase.data', names=column_names)\n",
        "df.head(10).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlDnx9uxWL6a",
        "outputId": "8fb1276f-5567-4107-f962-c5823b1cba2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4601 entries, 0 to 4600\n",
            "Data columns (total 58 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   word_freq_make              4601 non-null   float64\n",
            " 1   word_freq_address           4601 non-null   float64\n",
            " 2   word_freq_all               4601 non-null   float64\n",
            " 3   word_freq_3d                4601 non-null   float64\n",
            " 4   word_freq_our               4601 non-null   float64\n",
            " 5   word_freq_over              4601 non-null   float64\n",
            " 6   word_freq_remove            4601 non-null   float64\n",
            " 7   word_freq_internet          4601 non-null   float64\n",
            " 8   word_freq_order             4601 non-null   float64\n",
            " 9   word_freq_mail              4601 non-null   float64\n",
            " 10  word_freq_receive           4601 non-null   float64\n",
            " 11  word_freq_will              4601 non-null   float64\n",
            " 12  word_freq_people            4601 non-null   float64\n",
            " 13  word_freq_report            4601 non-null   float64\n",
            " 14  word_freq_addresses         4601 non-null   float64\n",
            " 15  word_freq_free              4601 non-null   float64\n",
            " 16  word_freq_business          4601 non-null   float64\n",
            " 17  word_freq_email             4601 non-null   float64\n",
            " 18  word_freq_you               4601 non-null   float64\n",
            " 19  word_freq_credit            4601 non-null   float64\n",
            " 20  word_freq_your              4601 non-null   float64\n",
            " 21  word_freq_font              4601 non-null   float64\n",
            " 22  word_freq_000               4601 non-null   float64\n",
            " 23  word_freq_money             4601 non-null   float64\n",
            " 24  word_freq_hp                4601 non-null   float64\n",
            " 25  word_freq_hpl               4601 non-null   float64\n",
            " 26  word_freq_george            4601 non-null   float64\n",
            " 27  word_freq_650               4601 non-null   float64\n",
            " 28  word_freq_lab               4601 non-null   float64\n",
            " 29  word_freq_labs              4601 non-null   float64\n",
            " 30  word_freq_telnet            4601 non-null   float64\n",
            " 31  word_freq_857               4601 non-null   float64\n",
            " 32  word_freq_data              4601 non-null   float64\n",
            " 33  word_freq_415               4601 non-null   float64\n",
            " 34  word_freq_85                4601 non-null   float64\n",
            " 35  word_freq_technology        4601 non-null   float64\n",
            " 36  word_freq_1999              4601 non-null   float64\n",
            " 37  word_freq_parts             4601 non-null   float64\n",
            " 38  word_freq_pm                4601 non-null   float64\n",
            " 39  word_freq_direct            4601 non-null   float64\n",
            " 40  word_freq_cs                4601 non-null   float64\n",
            " 41  word_freq_meeting           4601 non-null   float64\n",
            " 42  word_freq_original          4601 non-null   float64\n",
            " 43  word_freq_project           4601 non-null   float64\n",
            " 44  word_freq_re                4601 non-null   float64\n",
            " 45  word_freq_edu               4601 non-null   float64\n",
            " 46  word_freq_table             4601 non-null   float64\n",
            " 47  word_freq_conference        4601 non-null   float64\n",
            " 48  char_freq_;                 4601 non-null   float64\n",
            " 49  char_freq_(                 4601 non-null   float64\n",
            " 50  char_freq_[                 4601 non-null   float64\n",
            " 51  char_freq_!                 4601 non-null   float64\n",
            " 52  char_freq_$                 4601 non-null   float64\n",
            " 53  char_freq_#                 4601 non-null   float64\n",
            " 54  capital_run_length_average  4601 non-null   float64\n",
            " 55  capital_run_length_longest  4601 non-null   int64  \n",
            " 56  capital_run_length_total    4601 non-null   int64  \n",
            " 57  spam                        4601 non-null   int64  \n",
            "dtypes: float64(55), int64(3)\n",
            "memory usage: 2.0 MB\n"
          ]
        }
      ],
      "source": [
        "# sem dados ausentes\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEQCwTqTWL6b",
        "outputId": "e5e218f5-5078-401f-9cfc-69e12cf9a6d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3220, 57), (1381, 57), (3220,), (1381,))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# separando em conjunto de treino e de teste\n",
        "X = df.drop(columns=['spam'])\n",
        "y = df['spam']\n",
        "\n",
        "# divide o dataset em treino e teste, com stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "S8C8zl11WL6b"
      },
      "outputs": [],
      "source": [
        "# usando StratifiedKFold para garantir que seja feita uma amostragem estratificada durante o hypertuning\n",
        "stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wvuIzaoCWL6b"
      },
      "outputs": [],
      "source": [
        "# usando f1 como mtrica para o randomized search cross validation\n",
        "score = make_scorer(f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V2OqQdhFWL6c"
      },
      "outputs": [],
      "source": [
        "# dataset com scaling\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tid0LR-CWL6c"
      },
      "source": [
        "## Treinamento dos modelos\n",
        "Testaremos treinar com e sem usar scaling, para comparar os resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Btcp-qqbWL6c"
      },
      "source": [
        "### rvore de deciso\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S02q_MdWL6c"
      },
      "source": [
        "#### Sem Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erKh16_MWL6d",
        "outputId": "5136d2ce-d92e-4ec9-fa25-8d1f42787c5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.8701700154559505\n",
            "Recall: 0.8873128447596532\n",
            "F1-score: 0.8786578228638314\n"
          ]
        }
      ],
      "source": [
        "# Utilizando os hiperparmetros padres do scikit-learn\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "preds = cross_val_predict(dt_clf, X_train, y_train, cv=5)\n",
        "\n",
        "print(f\"Precision: {precision_score(y_train, preds)}\")\n",
        "print(f\"Recall: {recall_score(y_train, preds)}\")\n",
        "print(f\"F1-score: {f1_score(y_train, preds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOrs1prfWL6d"
      },
      "source": [
        "Tuning de hiperparmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyLsTUL3WL6d",
        "outputId": "663d2f3a-18c3-4bf0-f2bd-aa1ab43dbd96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "Melhores hiperparametros: {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 10}\n",
            "Melhor F1 score: 0.8897705246431116\n"
          ]
        }
      ],
      "source": [
        "dt_grid = {\n",
        "    'max_depth': [2, 4, 6, 8, 10, None],\n",
        "    'min_samples_split': [2, 4, 6, 8],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': [None, \"sqrt\", \"log2\"]\n",
        "}\n",
        "\n",
        "rs_dt = RandomizedSearchCV(\n",
        "    DecisionTreeClassifier(random_state=42),\n",
        "    dt_grid,\n",
        "    random_state=42,\n",
        "    n_iter=100,\n",
        "    scoring=score,\n",
        "    cv=stratified_cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "rs_dt.fit(X_train, y_train)\n",
        "print(f\"Melhores hiperparametros: {rs_dt.best_params_}\")\n",
        "print(f\"Melhor F1 score: {rs_dt.best_score_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZjxnB4NWL6e"
      },
      "source": [
        "#### Com scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyLy9ZuSWL6e",
        "outputId": "c0fb1f16-60a2-476c-c823-4275a09aa94a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.8688271604938271\n",
            "Recall: 0.8873128447596532\n",
            "F1-score: 0.877972709551657\n"
          ]
        }
      ],
      "source": [
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "preds = cross_val_predict(dt_clf, X_train_scaled, y_train, cv=5)\n",
        "\n",
        "print(f\"Precision: {precision_score(y_train, preds)}\")\n",
        "print(f\"Recall: {recall_score(y_train, preds)}\")\n",
        "print(f\"F1-score: {f1_score(y_train, preds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo0576C0WL6e",
        "outputId": "70850cbd-ef90-49bf-a6cf-5824badbce22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "Melhores hiperparametros: {'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 8}\n",
            "Melhor F1 score: 0.8894693778747339\n"
          ]
        }
      ],
      "source": [
        "dt_grid = {\n",
        "    'max_depth': [2, 4, 6, 8, 10, None],\n",
        "    'min_samples_split': [2, 4, 6, 8],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': [None, \"sqrt\", \"log2\"]\n",
        "}\n",
        "\n",
        "rs_dt = RandomizedSearchCV(\n",
        "    DecisionTreeClassifier(random_state=42),\n",
        "    dt_grid,\n",
        "    random_state=42,\n",
        "    n_iter=100,\n",
        "    scoring=score,\n",
        "    cv=stratified_cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "rs_dt.fit(X_train_scaled, y_train)\n",
        "print(f\"Melhores hiperparametros: {rs_dt.best_params_}\")\n",
        "print(f\"Melhor F1 score: {rs_dt.best_score_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxkKs9TVWL6e"
      },
      "source": [
        "No final das contas temos que o dataset sem scaling ficou com o f1 score levemente melhor que o dataset com scaling (88.97% contra 88.94%, no conjunto de validao do cross validation). A melhor combinao de hiperparmetros ficou como {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 10}."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoFxHcroTbkX"
      },
      "source": [
        "### Bayesiano ingnuo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MU-ye_vn3tJ"
      },
      "source": [
        "#### Sem scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdgJut5Jvq-e"
      },
      "source": [
        "##### Gaussiano"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQrXtc-Thuph",
        "outputId": "83fdff18-477e-4486-c228-f4105d5ebe13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.6954022988505747\n",
            "Recall: 0.9535066981875493\n",
            "F1-score: 0.8042539049518113\n"
          ]
        }
      ],
      "source": [
        "# Utilizando os hiperparmetros padres\n",
        "nb_clf = GaussianNB()\n",
        "preds = cross_val_predict(nb_clf, X_train, y_train, cv=5)\n",
        "\n",
        "print(f\"Precision: {precision_score(y_train, preds)}\")\n",
        "print(f\"Recall: {recall_score(y_train, preds)}\")\n",
        "print(f\"F1-score: {f1_score(y_train, preds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4-9Oc6IWsUR",
        "outputId": "e41d3095-028a-4c9e-8956-e02ca4986e42"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 8 is smaller than n_iter=100. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Melhores hiperparametros: {'var_smoothing': 1e-06}\n",
            "Melhor F1 score: 0.8263500183169544\n"
          ]
        }
      ],
      "source": [
        "nb_grid = {\n",
        "    'var_smoothing': [1e-11, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4],\n",
        "}\n",
        "\n",
        "rs_nb = RandomizedSearchCV(\n",
        "    estimator=GaussianNB(),\n",
        "    param_distributions=nb_grid,\n",
        "    random_state=42,\n",
        "    n_iter=100,\n",
        "    scoring=score,\n",
        "    cv=stratified_cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "rs_nb.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Melhores hiperparametros: {rs_nb.best_params_}\")\n",
        "print(f\"Melhor F1 score: {rs_nb.best_score_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqzKs7AcvyD7"
      },
      "source": [
        "##### Multinomial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17mqbzkQvyD8",
        "outputId": "38ca09e5-920c-43e8-ef53-5a24ee5a78b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.7377049180327869\n",
            "Recall: 0.7092198581560284\n",
            "F1-score: 0.7231820008035356\n"
          ]
        }
      ],
      "source": [
        "# Utilizando os hiperparmetros padres\n",
        "nb_clf = MultinomialNB()\n",
        "preds = cross_val_predict(nb_clf, X_train, y_train, cv=5)\n",
        "\n",
        "print(f\"Precision: {precision_score(y_train, preds)}\")\n",
        "print(f\"Recall: {recall_score(y_train, preds)}\")\n",
        "print(f\"F1-score: {f1_score(y_train, preds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PERNk3GOvyD-",
        "outputId": "22aba4ae-fdd1-4fc5-a00a-343f694290a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 10 is smaller than n_iter=100. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhores hiperparametros: {'fit_prior': False, 'alpha': 1e-08}\n",
            "Melhor F1 score: 0.7268401359077149\n"
          ]
        }
      ],
      "source": [
        "nb_grid = {\n",
        "    'alpha': [1e-3, 1e-2, 1e-1, 1e0, 1e1,],\n",
        "    'fit_prior': [True, False]\n",
        "}\n",
        "\n",
        "rs_nb = RandomizedSearchCV(\n",
        "    estimator=MultinomialNB(),\n",
        "    param_distributions=nb_grid,\n",
        "    random_state=42,\n",
        "    n_iter=100,\n",
        "    scoring=score,\n",
        "    cv=stratified_cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "rs_nb.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Melhores hiperparametros: {rs_nb.best_params_}\")\n",
        "print(f\"Melhor F1 score: {rs_nb.best_score_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRFZSOp36S40"
      },
      "source": [
        "##### Bernoulli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFUdM9ho6S48",
        "outputId": "5a5986ef-2955-4035-aedc-41f4dbdb3875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.8851063829787233\n",
            "Recall: 0.8195429472025216\n",
            "F1-score: 0.851063829787234\n"
          ]
        }
      ],
      "source": [
        "# Utilizando os hiperparmetros padres\n",
        "nb_clf = BernoulliNB()\n",
        "preds = cross_val_predict(nb_clf, X_train, y_train, cv=5)\n",
        "\n",
        "print(f\"Precision: {precision_score(y_train, preds)}\")\n",
        "print(f\"Recall: {recall_score(y_train, preds)}\")\n",
        "print(f\"F1-score: {f1_score(y_train, preds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58PmLcY26S4_",
        "outputId": "b7da315b-9d63-43b1-9eaa-a7fef615ef42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 50 is smaller than n_iter=100. Running 50 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhores hiperparametros: {'fit_prior': False, 'binarize': 0.1, 'alpha': 0.1}\n",
            "Melhor F1 score: 0.8730489796102455\n"
          ]
        }
      ],
      "source": [
        "nb_grid = {\n",
        "    'binarize': [1e-3, 1e-2, 1e-1, 1e0, 1e1,],\n",
        "    'alpha': [1e-3, 1e-2, 1e-1, 1e0, 1e1,],\n",
        "    'fit_prior': [True, False]\n",
        "}\n",
        "\n",
        "rs_nb = RandomizedSearchCV(\n",
        "    estimator=BernoulliNB(),\n",
        "    param_distributions=nb_grid,\n",
        "    random_state=42,\n",
        "    n_iter=100,\n",
        "    scoring=score,\n",
        "    cv=stratified_cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "rs_nb.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Melhores hiperparametros: {rs_nb.best_params_}\")\n",
        "print(f\"Melhor F1 score: {rs_nb.best_score_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sarXPbHSAnDP"
      },
      "source": [
        "#### Com scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSRUAE64AnDT"
      },
      "source": [
        "##### Gaussiano"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfIKf70SAnDU",
        "outputId": "9a64ce5b-0d05-4a90-bb04-58035e931ea5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.6856659142212189\n",
            "Recall: 0.9574468085106383\n",
            "F1-score: 0.7990792502466294\n"
          ]
        }
      ],
      "source": [
        "# Utilizando os hiperparmetros padres\n",
        "nb_clf = GaussianNB()\n",
        "preds = cross_val_predict(nb_clf, X_train_scaled, y_train, cv=5)\n",
        "\n",
        "print(f\"Precision: {precision_score(y_train, preds)}\")\n",
        "print(f\"Recall: {recall_score(y_train, preds)}\")\n",
        "print(f\"F1-score: {f1_score(y_train, preds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZRrrRGlAnDV",
        "outputId": "a103f4d1-0994-4661-8296-47d676236737"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 8 is smaller than n_iter=100. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Melhores hiperparametros: {'var_smoothing': 1e-05}\n",
            "Melhor F1 score: 0.8038195005253103\n"
          ]
        }
      ],
      "source": [
        "nb_grid = {\n",
        "    'var_smoothing': [1e-11, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4],\n",
        "}\n",
        "\n",
        "rs_nb = RandomizedSearchCV(\n",
        "    estimator=GaussianNB(),\n",
        "    param_distributions=nb_grid,\n",
        "    random_state=42,\n",
        "    n_iter=100,\n",
        "    scoring=score,\n",
        "    cv=stratified_cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "rs_nb.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"Melhores hiperparametros: {rs_nb.best_params_}\")\n",
        "print(f\"Melhor F1 score: {rs_nb.best_score_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7meeq6JAnDW"
      },
      "source": [
        "##### Multinomial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdWkG-GJAnDX",
        "outputId": "a7c9726d-af00-43f5-96c4-af8e8ca7e9f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.9276315789473685\n",
            "Recall: 0.7777777777777778\n",
            "F1-score: 0.8461208744106301\n"
          ]
        }
      ],
      "source": [
        "# Utilizando os hiperparmetros padres\n",
        "nb_clf = MultinomialNB()\n",
        "preds = cross_val_predict(nb_clf, X_train_scaled, y_train, cv=5)\n",
        "\n",
        "print(f\"Precision: {precision_score(y_train, preds)}\")\n",
        "print(f\"Recall: {recall_score(y_train, preds)}\")\n",
        "print(f\"F1-score: {f1_score(y_train, preds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lToYXW3AnDZ",
        "outputId": "5bf14f0d-5c5f-41f8-de8d-adb521bc79cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 10 is smaller than n_iter=100. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Melhores hiperparametros: {'fit_prior': True, 'alpha': 1e-05}\n",
            "Melhor F1 score: 0.8528650943530615\n"
          ]
        }
      ],
      "source": [
        "nb_grid = {\n",
        "    'alpha': [1e-3, 1e-2, 1e-1, 1e0, 1e1,],\n",
        "    'fit_prior': [True, False]\n",
        "}\n",
        "\n",
        "rs_nb = RandomizedSearchCV(\n",
        "    estimator=MultinomialNB(),\n",
        "    param_distributions=nb_grid,\n",
        "    random_state=42,\n",
        "    n_iter=100,\n",
        "    scoring=score,\n",
        "    cv=stratified_cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "rs_nb.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"Melhores hiperparametros: {rs_nb.best_params_}\")\n",
        "print(f\"Melhor F1 score: {rs_nb.best_score_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8hK1TECAnDa"
      },
      "source": [
        "##### Bernoulli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4FVHip_AnDb",
        "outputId": "cc7881a2-8dc2-4b4b-a830-41b7558c12bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.877104377104377\n",
            "Recall: 0.8211189913317573\n",
            "F1-score: 0.8481888481888482\n"
          ]
        }
      ],
      "source": [
        "# Utilizando os hiperparmetros padres\n",
        "nb_clf = BernoulliNB()\n",
        "preds = cross_val_predict(nb_clf, X_train_scaled, y_train, cv=5)\n",
        "\n",
        "print(f\"Precision: {precision_score(y_train, preds)}\")\n",
        "print(f\"Recall: {recall_score(y_train, preds)}\")\n",
        "print(f\"F1-score: {f1_score(y_train, preds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lIRT0IWAnDc",
        "outputId": "66be2685-5fc3-400a-aba6-4dc9ec2a1c6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 50 is smaller than n_iter=100. Running 50 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Melhores hiperparametros: {'fit_prior': False, 'binarize': 0.01, 'alpha': 1.0}\n",
            "Melhor F1 score: 0.8696767144558869\n"
          ]
        }
      ],
      "source": [
        "nb_grid = {\n",
        "    'binarize': [1e-3, 1e-2, 1e-1, 1e0, 1e1,],\n",
        "    'alpha': [1e-3, 1e-2, 1e-1, 1e0, 1e1,],\n",
        "    'fit_prior': [True, False]\n",
        "}\n",
        "\n",
        "rs_nb = RandomizedSearchCV(\n",
        "    estimator=BernoulliNB(),\n",
        "    param_distributions=nb_grid,\n",
        "    random_state=42,\n",
        "    n_iter=100,\n",
        "    scoring=score,\n",
        "    cv=stratified_cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "rs_nb.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"Melhores hiperparametros: {rs_nb.best_params_}\")\n",
        "print(f\"Melhor F1 score: {rs_nb.best_score_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olhupq8tEL22"
      },
      "source": [
        "O melhor resultado obtido se deu no Naive Bayes Bernoulli sem escaling com um F1 Score de 0.8730489796102455. Os melhores hiperparametros foram {'fit_prior': False, 'binarize': 0.1, 'alpha': 0.1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olvzi8wAWL6f"
      },
      "source": [
        "### Regresso Logstica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQVbmJAq30fx"
      },
      "source": [
        "#### Definindo o modelo de regresso logstica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7kfm1Nj3-sR"
      },
      "outputs": [],
      "source": [
        "# Criando o modelo de regresso logstica\n",
        "log_reg = LogisticRegression(random_state=42, max_iter=2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZjO9_vd4DDJ"
      },
      "source": [
        "#### Sem Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCB07sNQ4LcI",
        "outputId": "6a358bbb-152a-417f-e88f-66e459e658df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.9131832797427653\n",
            "Recall: 0.8951930654058313\n",
            "F1-score: 0.9040986868284918\n"
          ]
        }
      ],
      "source": [
        "# Treinamento sem scaling, utilizando validao cruzada\n",
        "preds = cross_val_predict(log_reg, X_train, y_train, cv=5)\n",
        "\n",
        "# Avaliando as mtricas de desempenho\n",
        "print(f\"Precision: {precision_score(y_train, preds)}\")\n",
        "print(f\"Recall: {recall_score(y_train, preds)}\")\n",
        "print(f\"F1-score: {f1_score(y_train, preds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVTETpKj4YvQ"
      },
      "source": [
        "Tuning de hiperparmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeC1cMXw4lXw",
        "outputId": "cf93a742-aedd-41e9-c83b-9a80f614cea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhores hiperparmetros: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.31622776601683794}\n",
            "Melhor F1 score: 0.9000972808921993\n"
          ]
        }
      ],
      "source": [
        "# Definio da grade de hiperparmetros corrigida\n",
        "param_grid = {\n",
        "    'solver': ['liblinear', 'saga'],  # 'liblinear' suporta apenas 'l1' e 'l2'; 'saga' suporta 'elasticnet' tambm\n",
        "    'penalty': ['l1', 'l2'],  # Removendo 'none' pois causa erro\n",
        "    'C': np.logspace(-2, 1, 5)  # [0.01, 0.1, 1, 10, 100] Valores de regularizao\n",
        "}\n",
        "\n",
        "# Criando o modelo base\n",
        "log_reg = LogisticRegression(max_iter=7000)  # Aumentando max_iter para evitar erro de convergncia\n",
        "\n",
        "# RandomizedSearchCV corrigido\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=log_reg,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=6,\n",
        "    cv=5,\n",
        "    scoring='f1',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Ajustando o modelo\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Exibindo os melhores hiperparmetros\n",
        "print(\"Melhores hiperparmetros:\", random_search.best_params_)\n",
        "print(\"Melhor F1 score:\", random_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQdqhw_eDARn"
      },
      "source": [
        "#### Com scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz4Ox-oYDDG-",
        "outputId": "bb9ce32a-2d9a-437c-ce0c-3f6d933175a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision (com scaling): 0.9000900090009001\n",
            "Recall (com scaling): 0.7880220646178093\n",
            "F1-score (com scaling): 0.8403361344537815\n"
          ]
        }
      ],
      "source": [
        "# Usando o MinMaxScaler para escalonar os dados\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Treinando o modelo com validao cruzada nos dados escalonados\n",
        "preds_scaled = cross_val_predict(log_reg, X_train_scaled, y_train, cv=5)\n",
        "\n",
        "# Avaliando as mtricas de desempenho nos dados escalonados\n",
        "print(f\"Precision (com scaling): {precision_score(y_train, preds_scaled)}\")\n",
        "print(f\"Recall (com scaling): {recall_score(y_train, preds_scaled)}\")\n",
        "print(f\"F1-score (com scaling): {f1_score(y_train, preds_scaled)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZIhqefND3Cs"
      },
      "source": [
        "Tuning de Hiperparmetros (com scaling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qghrXa6aD65s",
        "outputId": "e01c4f77-8cb9-4f74-a093-91aa92411a82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Melhores hiperparmetros (com scaling): {'solver': 'saga', 'penalty': 'l1', 'C': 10.0}\n",
            "Melhor F1 score (com scaling): 0.9037401630812191\n"
          ]
        }
      ],
      "source": [
        "# Usando os mesmos hiperparmetros, mas agora para os dados escalonados\n",
        "rs_log_reg_scaled = RandomizedSearchCV(\n",
        "    log_reg,\n",
        "    param_grid,\n",
        "    random_state=42,\n",
        "    n_iter=20,\n",
        "    scoring='f1',\n",
        "    cv=stratified_cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Treinando o modelo com os melhores hiperparmetros para dados escalonados\n",
        "rs_log_reg_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Exibindo os melhores hiperparmetros\n",
        "print(f\"Melhores hiperparmetros (com scaling): {rs_log_reg_scaled.best_params_}\")\n",
        "print(f\"Melhor F1 score (com scaling): {rs_log_reg_scaled.best_score_}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CTZBsAhWL6f"
      },
      "source": [
        "### K-Vizinhos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Definindo o modelo de K-Vizinhos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "knn_clf = KNeighborsClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sem Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.7332796132151491\n",
            "Recall: 0.7171000788022065\n",
            "F1-score: 0.7250996015936255\n"
          ]
        }
      ],
      "source": [
        "# Treinamento sem scaling, utilizando validao cruzada\n",
        "preds = cross_val_predict(knn_clf, X_train, y_train, cv=5)\n",
        "\n",
        "# Avaliando as mtricas de desempenho\n",
        "print(f\"Precision: {precision_score(y_train, preds)}\")\n",
        "print(f\"Recall: {recall_score(y_train, preds)}\")\n",
        "print(f\"F1-score: {f1_score(y_train, preds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tuning de Hiperparmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhores hiperparmetros: {'weights': 'distance', 'n_neighbors': 7, 'metric': 'manhattan'}\n",
            "Melhor F1 score: 0.8099647934411882\n"
          ]
        }
      ],
      "source": [
        "# Definio da grade de hiperparmetros\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],  # Nmero de vizinhos\n",
        "    'weights': ['uniform', 'distance'],  # Pesos dos vizinhos\n",
        "    'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']  # Mtrica de distncia\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=knn_clf,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=20,\n",
        "    cv=5,\n",
        "    scoring='f1',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Ajustando o modelo\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Exibindo os melhores hiperparmetros\n",
        "print(\"Melhores hiperparmetros:\", random_search.best_params_)\n",
        "print(\"Melhor F1 score:\", random_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Com Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision (com scaling): 0.8740801308258381\n",
            "Recall (com scaling): 0.8423955870764381\n",
            "F1-score (com scaling): 0.8579454253611557\n"
          ]
        }
      ],
      "source": [
        "# Treinamento com scaling, utilizando validao cruzada\n",
        "preds_scaled = cross_val_predict(knn_clf, X_train_scaled, y_train, cv=5)\n",
        "\n",
        "# Avaliando as mtricas de desempenho\n",
        "print(f\"Precision (com scaling): {precision_score(y_train, preds_scaled)}\")\n",
        "print(f\"Recall (com scaling): {recall_score(y_train, preds_scaled)}\")\n",
        "print(f\"F1-score (com scaling): {f1_score(y_train, preds_scaled)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tuning de Hiperparmetros (com scaling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhores hiperparmetros (com scaling): {'weights': 'distance', 'n_neighbors': 5, 'metric': 'manhattan'}\n",
            "Melhor F1 score (com scaling): 0.8766526915769756\n"
          ]
        }
      ],
      "source": [
        "# Ajustando o modelo\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Exibindo os melhores hiperparmetros\n",
        "print(\"Melhores hiperparmetros (com scaling):\", random_search.best_params_)\n",
        "print(\"Melhor F1 score (com scaling):\", random_search.best_score_)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
